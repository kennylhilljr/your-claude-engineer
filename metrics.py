"""Agent Status Dashboard - Metrics Data Model.

This module defines the core TypedDict classes for tracking agent performance metrics,
session data, and dashboard state. These types provide structure for the metrics
collection system that instruments agent delegations and tracks their contributions.

The data model consists of four main types:
- AgentEvent: Records a single agent invocation with tokens, cost, and artifacts
- AgentProfile: Cumulative statistics and gamification data for each agent
- SessionSummary: Rollup metrics for an entire session
- DashboardState: Root structure containing all metrics data

All timestamps use ISO 8601 format. Token counts and costs are tracked per-event
and aggregated into agent profiles and session summaries.
"""

from typing import Literal, TypedDict


class AgentEvent(TypedDict):
    """Single agent invocation record.

    Captures one delegation to an agent (coding, github, linear, slack, etc.)
    or one session invocation. Tracks execution time, token usage, cost,
    artifacts produced, and any errors encountered.
    """

    event_id: str                                           # UUID identifier for this event
    agent_name: str                                         # Agent type: "coding", "github", "linear", "slack", etc.
    session_id: str                                         # Parent session identifier linking related events
    ticket_key: str                                         # Linear ticket key if applicable (e.g., "AI-44")
    started_at: str                                         # ISO 8601 timestamp when agent invocation began
    ended_at: str                                           # ISO 8601 timestamp when agent invocation completed
    duration_seconds: float                                 # Total execution time in seconds
    status: Literal["success", "error", "timeout", "blocked"]  # Final outcome status

    # Token tracking - counts from the LLM API response
    input_tokens: int                                       # Tokens in the prompt/context
    output_tokens: int                                      # Tokens generated by the model
    total_tokens: int                                       # Sum of input and output tokens
    estimated_cost_usd: float                               # Cost in USD based on model pricing

    # Contribution artifacts - what the agent produced
    artifacts: list[str]                                    # List of artifacts: ["commit:abc123", "pr:#42", "file:src/foo.py", "issue:AI-12"]
    error_message: str                                      # Error details if status is "error", empty string if success
    model_used: str                                         # Model identifier: "claude-haiku-4-5", "claude-sonnet-4-5", etc.


class AgentProfile(TypedDict):
    """Cumulative performance profile for one agent.

    Aggregates lifetime statistics, contribution counters, derived metrics,
    and gamification data for a single agent. Profiles are keyed by agent_name
    in the DashboardState and updated after each agent invocation.
    """

    agent_name: str                                         # Agent identifier (must match event agent_name)

    # Lifetime counters - aggregated from all agent events
    total_invocations: int                                  # Total number of times this agent was invoked
    successful_invocations: int                             # Count of events with status="success"
    failed_invocations: int                                 # Count of events with status in ["error", "timeout", "blocked"]
    total_tokens: int                                       # Sum of all token usage across events
    total_cost_usd: float                                   # Sum of all estimated costs in USD
    total_duration_seconds: float                           # Sum of all execution durations

    # Contribution counters - specific to agent capabilities
    commits_made: int                                       # GitHub agent: commits created
    prs_created: int                                        # GitHub agent: pull requests opened
    prs_merged: int                                         # GitHub agent: pull requests merged
    files_created: int                                      # Coding agent: new files written
    files_modified: int                                     # Coding agent: existing files edited
    lines_added: int                                        # Coding agent: lines of code added
    lines_removed: int                                      # Coding agent: lines of code removed
    tests_written: int                                      # Coding agent: test files/cases created
    issues_created: int                                     # Linear agent: issues created
    issues_completed: int                                   # Linear agent: issues closed
    messages_sent: int                                      # Slack agent: messages posted
    reviews_completed: int                                  # PR Reviewer agent: reviews submitted

    # Derived metrics - recalculated on read from counters
    success_rate: float                                     # successful_invocations / total_invocations (0.0 to 1.0)
    avg_duration_seconds: float                             # total_duration_seconds / total_invocations
    avg_tokens_per_call: float                              # total_tokens / total_invocations
    cost_per_success_usd: float                             # total_cost_usd / successful_invocations

    # Gamification - XP, levels, and achievements
    xp: int                                                 # Experience points earned from successful invocations
    level: int                                              # Current level derived from XP thresholds
    current_streak: int                                     # Consecutive successful invocations
    best_streak: int                                        # Highest consecutive success streak achieved
    achievements: list[str]                                 # Achievement badges: ["first_blood", "century_club", "perfect_day", ...]

    # Strengths and weaknesses - auto-detected from metrics
    strengths: list[str]                                    # Positive attributes: ["fast_execution", "high_success_rate", "low_cost"]
    weaknesses: list[str]                                   # Areas for improvement: ["high_error_rate", "slow", "expensive"]

    # Recent history - rolling window for drill-down
    recent_events: list[str]                                # Last 20 event_ids for detailed analysis
    last_error: str                                         # Most recent error_message from failed events
    last_active: str                                        # ISO 8601 timestamp of most recent event


class SessionSummary(TypedDict):
    """Per-session rollup metrics.

    Summarizes an entire session (initializer or continuation) including
    all agents invoked, total resource usage, and tickets worked. Sessions
    are stored in chronological order in DashboardState.sessions.
    """

    session_id: str                                         # Unique session identifier
    session_number: int                                     # Sequential session number within project
    session_type: Literal["initializer", "continuation"]    # Session category
    started_at: str                                         # ISO 8601 timestamp when session began
    ended_at: str                                           # ISO 8601 timestamp when session completed
    status: Literal["continue", "error", "complete"]        # Session outcome
    agents_invoked: list[str]                               # List of agent names used in this session
    total_tokens: int                                       # Sum of tokens from all events in session
    total_cost_usd: float                                   # Sum of costs from all events in session
    tickets_worked: list[str]                               # List of ticket keys addressed in this session


class DashboardState(TypedDict):
    """Root structure of .agent_metrics.json.

    Top-level container for all metrics data. Persisted to disk after each
    session and loaded at startup. Contains global counters, per-agent profiles,
    event log, and session history.
    """

    version: int                                            # Schema version number (currently 1)
    project_name: str                                       # Name of the project being tracked
    created_at: str                                         # ISO 8601 timestamp when metrics file was created
    updated_at: str                                         # ISO 8601 timestamp of last update

    # Global counters - aggregated across all sessions and agents
    total_sessions: int                                     # Count of all sessions recorded
    total_tokens: int                                       # Sum of tokens across all events
    total_cost_usd: float                                   # Sum of costs across all events
    total_duration_seconds: float                           # Sum of durations across all events

    # Per-agent profiles - cumulative statistics keyed by agent name
    agents: dict[str, AgentProfile]                         # Dictionary mapping agent_name to AgentProfile

    # Event log - append-only history of agent invocations (capped at 500)
    events: list[AgentEvent]                                # Chronological list of all agent events

    # Session history - recent session summaries (last 50 sessions)
    sessions: list[SessionSummary]                          # Chronological list of session rollups
