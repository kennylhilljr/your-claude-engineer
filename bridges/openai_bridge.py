"""
OpenAI ChatGPT Bridge Module
=============================
Wraps ChatGPT/OpenAI interaction to provide a unified interface for the
multi-AI orchestrator. Supports two authentication modes:
1. Codex OAuth (Primary) - Uses OpenAI Codex CLI's "Sign in with ChatGPT" flow.
2. Session Token (Alternative) - Uses browser session cookie. Zero API cost.

Environment Variables:
    CHATGPT_AUTH_TYPE: "codex-oauth" (default) or "session-token"
    OPENAI_API_KEY: API key (auto-generated by Codex CLI or manually set)
    CHATGPT_SESSION_TOKEN: Browser session token (for session-token auth)
    CHATGPT_MODEL: Default model - gpt-4o, o1, o3-mini, o4-mini (default: gpt-4o)
"""

import json
import os
import subprocess
import uuid
from collections.abc import AsyncIterator
from dataclasses import dataclass, field
from enum import StrEnum

try:
    import httpx
except ImportError:
    httpx = None

try:
    from openai import AsyncOpenAI, OpenAI
except ImportError:
    AsyncOpenAI = None
    OpenAI = None


class AuthType(StrEnum):
    CODEX_OAUTH = "codex-oauth"
    SESSION_TOKEN = "session-token"


class ChatGPTModel(StrEnum):
    GPT_4O = "gpt-4o"
    O1 = "o1"
    O3_MINI = "o3-mini"
    O4_MINI = "o4-mini"

    @classmethod
    def from_string(cls, value: str) -> "ChatGPTModel":
        mapping = {m.value: m for m in cls}
        return mapping.get(value.lower().strip(), cls.GPT_4O)


@dataclass
class ChatMessage:
    role: str
    content: str


@dataclass
class ChatSession:
    model: ChatGPTModel
    messages: list[ChatMessage] = field(default_factory=list)
    session_id: str | None = None

    def add_message(self, role: str, content: str) -> None:
        self.messages.append(ChatMessage(role=role, content=content))

    def to_openai_messages(self) -> list[dict[str, str]]:
        return [{"role": m.role, "content": m.content} for m in self.messages]


@dataclass
class ChatResponse:
    content: str
    model: str
    usage: dict | None = None
    finish_reason: str | None = None


class CodexOAuthClient:
    """Primary path: Uses OpenAI SDK with API key from Codex CLI OAuth flow."""

    def __init__(self, api_key: str | None = None):
        if OpenAI is None or AsyncOpenAI is None:
            raise ImportError("openai package not installed. Run: pip install openai")
        self.api_key = api_key or os.environ.get("OPENAI_API_KEY", "")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not set. Run 'codex' to sign in, or set manually.")
        self._client = OpenAI(api_key=self.api_key)
        self._async_client = AsyncOpenAI(api_key=self.api_key)

    def send_message(
        self, session: ChatSession, message: str, stream: bool = False
    ) -> ChatResponse:
        session.add_message("user", message)
        response = self._client.chat.completions.create(
            model=session.model.value, messages=session.to_openai_messages(), stream=False
        )
        content = response.choices[0].message.content or ""
        session.add_message("assistant", content)
        return ChatResponse(
            content=content,
            model=response.model,
            usage={
                "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                "completion_tokens": response.usage.completion_tokens if response.usage else 0,
                "total_tokens": response.usage.total_tokens if response.usage else 0,
            },
            finish_reason=response.choices[0].finish_reason,
        )

    async def send_message_async(self, session: ChatSession, message: str) -> ChatResponse:
        session.add_message("user", message)
        response = await self._async_client.chat.completions.create(
            model=session.model.value, messages=session.to_openai_messages(), stream=False
        )
        content = response.choices[0].message.content or ""
        session.add_message("assistant", content)
        return ChatResponse(
            content=content,
            model=response.model,
            usage={
                "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                "completion_tokens": response.usage.completion_tokens if response.usage else 0,
                "total_tokens": response.usage.total_tokens if response.usage else 0,
            },
            finish_reason=response.choices[0].finish_reason,
        )

    async def stream_response(self, session: ChatSession, message: str) -> AsyncIterator[str]:
        session.add_message("user", message)
        stream = await self._async_client.chat.completions.create(
            model=session.model.value, messages=session.to_openai_messages(), stream=True
        )
        full_content = ""
        async for chunk in stream:
            if chunk.choices and chunk.choices[0].delta.content:
                token = chunk.choices[0].delta.content
                full_content += token
                yield token
        session.add_message("assistant", full_content)


class SessionTokenClient:
    """Alternative path: Uses ChatGPT web session token for zero API cost.

    Uses curl_cffi to impersonate Chrome's TLS fingerprint, bypassing
    Cloudflare's bot detection on chatgpt.com.
    """

    CHATGPT_BASE_URL = "https://chatgpt.com"
    BACKEND_API_URL = f"{CHATGPT_BASE_URL}/backend-api"

    # Browser-like headers that match a real Chrome session
    _BROWSER_HEADERS = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/131.0.0.0 Safari/537.36",
        "Accept": "*/*",
        "Accept-Language": "en-US,en;q=0.9",
        "Accept-Encoding": "gzip, deflate, br",
        "Sec-Ch-Ua": '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
        "Sec-Ch-Ua-Mobile": "?0",
        "Sec-Ch-Ua-Platform": '"macOS"',
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "Origin": "https://chatgpt.com",
        "Referer": "https://chatgpt.com/",
    }

    def __init__(self, session_token: str | None = None):
        try:
            from curl_cffi.requests import Session as CffiSession

            self._CffiSession = CffiSession
        except ImportError:
            raise ImportError(
                "curl_cffi package not installed. Run: pip install curl_cffi\n"
                "This is needed to bypass Cloudflare's TLS fingerprinting."
            )
        self.session_token = session_token or os.environ.get("CHATGPT_SESSION_TOKEN", "")
        if not self.session_token:
            raise ValueError("CHATGPT_SESSION_TOKEN not set.")
        self._access_token: str | None = None
        # Persistent session preserves Cloudflare cookies across requests
        self._http: object | None = None

    def _get_http(self):
        """Get or create a persistent HTTP session with Chrome impersonation."""
        if self._http is None:
            self._http = self._CffiSession(impersonate="chrome")
            # Seed the session cookie
            self._http.cookies.set(
                "__Secure-next-auth.session-token",
                self.session_token,
                domain="chatgpt.com",
            )
        return self._http

    def _get_headers(self) -> dict[str, str]:
        if not self._access_token:
            self._refresh_access_token()
        return {
            **self._BROWSER_HEADERS,
            "Authorization": f"Bearer {self._access_token}",
            "Content-Type": "application/json",
        }

    def _refresh_access_token(self) -> None:
        s = self._get_http()
        # First, hit the main page to get Cloudflare clearance cookies
        s.get(self.CHATGPT_BASE_URL, headers=self._BROWSER_HEADERS)
        # Then exchange session token for access token
        response = s.get(
            f"{self.CHATGPT_BASE_URL}/api/auth/session",
            headers=self._BROWSER_HEADERS,
        )
        response.raise_for_status()
        data = response.json()
        self._access_token = data.get("accessToken")
        if not self._access_token:
            raise ValueError("Failed to get access token. Session token may be expired.")

    def send_message(
        self, session: ChatSession, message: str, stream: bool = False
    ) -> ChatResponse:
        session.add_message("user", message)
        payload = {
            "action": "next",
            "messages": [
                {
                    "id": str(uuid.uuid4()),
                    "author": {"role": "user"},
                    "content": {"content_type": "text", "parts": [message]},
                }
            ],
            "model": session.model.value,
            "parent_message_id": str(uuid.uuid4()),
        }
        if session.session_id:
            payload["conversation_id"] = session.session_id
        s = self._get_http()
        response = s.post(
            f"{self.BACKEND_API_URL}/conversation", headers=self._get_headers(), json=payload
        )
        if response.status_code == 401:
            self._refresh_access_token()
            response = s.post(
                f"{self.BACKEND_API_URL}/conversation", headers=self._get_headers(), json=payload
            )
        response.raise_for_status()
        content = ""
        for line in response.text.split("\n"):
            if line.startswith("data: ") and line != "data: [DONE]":
                try:
                    data = json.loads(line[6:])
                    if "message" in data:
                        parts = data["message"]["content"].get("parts", [])
                        if parts:
                            content = parts[0]
                        if "conversation_id" in data:
                            session.session_id = data["conversation_id"]
                except (json.JSONDecodeError, KeyError, IndexError):
                    continue
        session.add_message("assistant", content)
        return ChatResponse(
            content=content, model=session.model.value, usage=None, finish_reason="stop"
        )


class OpenAIBridge:
    """Unified bridge for ChatGPT access."""

    def __init__(self, auth_type: AuthType, client):
        self.auth_type = auth_type
        self._client = client

    @classmethod
    def from_env(cls) -> "OpenAIBridge":
        auth_type_str = os.environ.get("CHATGPT_AUTH_TYPE", "codex-oauth")
        try:
            auth_type = AuthType(auth_type_str.lower().strip())
        except ValueError:
            print(
                f"Warning: Unknown CHATGPT_AUTH_TYPE '{auth_type_str}', falling back to codex-oauth"
            )
            auth_type = AuthType.CODEX_OAUTH
        if auth_type == AuthType.CODEX_OAUTH:
            client = CodexOAuthClient()
        else:
            client = SessionTokenClient()
        return cls(auth_type=auth_type, client=client)

    def create_session(
        self, model: str | None = None, system_prompt: str | None = None
    ) -> ChatSession:
        model_str = model or os.environ.get("CHATGPT_MODEL", "gpt-4o")
        chat_model = ChatGPTModel.from_string(model_str)
        session = ChatSession(model=chat_model)
        if system_prompt:
            session.add_message("system", system_prompt)
        return session

    def send_message(self, session: ChatSession, message: str) -> ChatResponse:
        return self._client.send_message(session, message)

    async def send_message_async(self, session: ChatSession, message: str) -> ChatResponse:
        if hasattr(self._client, "send_message_async"):
            return await self._client.send_message_async(session, message)
        return self._client.send_message(session, message)

    async def stream_response(self, session: ChatSession, message: str) -> AsyncIterator[str]:
        if hasattr(self._client, "stream_response"):
            async for token in self._client.stream_response(session, message):
                yield token
        else:
            response = self._client.send_message(session, message)
            yield response.content

    def get_auth_info(self) -> dict[str, str]:
        info = {
            "auth_type": self.auth_type.value,
            "model_default": os.environ.get("CHATGPT_MODEL", "gpt-4o"),
        }
        if self.auth_type == AuthType.CODEX_OAUTH:
            key = os.environ.get("OPENAI_API_KEY", "")
            info["api_key_set"] = "yes" if key else "no"
            info["api_key_prefix"] = key[:8] + "..." if len(key) > 8 else "(short)"
            info["cost_note"] = "Using Codex OAuth. Monitor usage at platform.openai.com/usage"
        else:
            token = os.environ.get("CHATGPT_SESSION_TOKEN", "")
            info["session_token_set"] = "yes" if token else "no"
            info["cost_note"] = "Using session token. Zero API cost."
        return info


def check_codex_cli_installed() -> bool:
    try:
        result = subprocess.run(["codex", "--version"], capture_output=True, text=True, timeout=10)
        return result.returncode == 0
    except (FileNotFoundError, subprocess.TimeoutExpired):
        return False


def get_available_models() -> list[str]:
    return [m.value for m in ChatGPTModel]


def print_auth_status() -> None:
    try:
        bridge = OpenAIBridge.from_env()
        info = bridge.get_auth_info()
        print("ChatGPT Authentication Status:")
        for key, value in info.items():
            print(f"  {key}: {value}")
    except (ValueError, ImportError) as e:
        print(f"ChatGPT authentication error: {e}")
